#!/usr/bin/env python3
"""
Script principal pour FastDetectGPT avec interface utilisateur am√©lior√©e
"""

import argparse
import os
import time
import torch
import numpy as np
from fast_detect_gpt import FastDetectGPT, sigmoid

def analyze_text(detector, text):
    """Analyse un texte et affiche les r√©sultats"""
    import time
    
    print("\nAnalyse en cours...")
    start_time = time.time()
    
    prob, crit, ntokens = detector.compute_prob(text)
    
    duration = time.time() - start_time
    
    print("\nR√©sultats de l'analyse:")
    print(f"- Nombre de tokens: {ntokens}")
    print(f"- Score du crit√®re: {crit:.4f}")
    print(f"- Probabilit√© d'√™tre g√©n√©r√© par IA: {prob * 100:.1f}%")
    print(f"- Temps d'analyse: {duration:.2f} secondes")
    
    # Interpr√©tation des r√©sultats
    print("\nInterpr√©tation:")
    if prob < 0.3:
        print("‚úÖ Ce texte est tr√®s probablement √©crit par un humain.")
    elif prob < 0.7:
        print("‚ö†Ô∏è R√©sultat incertain - le texte pr√©sente des caract√©ristiques mixtes.")
    else:
        print("ü§ñ Ce texte est tr√®s probablement g√©n√©r√© par une IA.")
    
    # Conseils pour am√©liorer la d√©tection
    if ntokens < 100:
        print("\nNote: Le texte est court, ce qui peut affecter la fiabilit√© de la d√©tection.")
        print("Pour de meilleurs r√©sultats, utilisez des textes plus longs (>200 tokens).")

def run_improved(args):
    """Interface utilisateur am√©lior√©e pour FastDetectGPT"""
    detector = FastDetectGPT(args)
    print('FastDetectGPT - D√©tecteur de texte g√©n√©r√© par IA')
    print('-----------------------------------------------')
    print(f'Mod√®le de r√©f√©rence: {args.reference_model_name}')
    print(f'Mod√®le de scoring: {args.scoring_model_name}')
    print('-----------------------------------------------')
    
    while True:
        print("\nChoisissez une option:")
        print("1. Analyser un texte saisi manuellement")
        print("2. Analyser un fichier texte")
        print("3. Analyser plusieurs fichiers (mode batch)")
        print("4. Quitter")
        
        choice = input("\nVotre choix (1-4): ")
        
        if choice == '1':
            print("\nEntrez votre texte (appuyez sur Entr√©e deux fois pour commencer l'analyse):")
            lines = []
            while True:
                line = input()
                if len(line) == 0:
                    break
                lines.append(line)
            text = "\n".join(lines)
            
            if len(text) == 0:
                print("Aucun texte saisi.")
                continue
                
            analyze_text(detector, text)
            
        elif choice == '2':
            file_path = input("\nEntrez le chemin du fichier: ")
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                print(f"\nAnalyse du fichier: {file_path} ({len(text)} caract√®res)")
                analyze_text(detector, text)
            except Exception as e:
                print(f"Erreur lors de la lecture du fichier: {e}")
                
        elif choice == '3':
            dir_path = input("\nEntrez le chemin du dossier contenant les fichiers texte: ")
            file_pattern = input("Entrez le motif de fichier (ex: *.txt): ")
            output_path = input("Entrez le chemin du fichier de r√©sultats (ex: results.csv): ")
            
            try:
                import glob
                import os
                import csv
                
                files = glob.glob(os.path.join(dir_path, file_pattern))
                print(f"\nAnalyse de {len(files)} fichiers...")
                
                with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(['Fichier', 'Probabilit√© IA (%)', 'Score', 'Tokens'])
                    
                    for file_path in files:
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                text = f.read()
                            
                            prob, crit, ntokens = detector.compute_prob(text)
                            writer.writerow([file_path, f"{prob * 100:.1f}", f"{crit:.4f}", ntokens])
                            print(f"Analys√©: {file_path} - Probabilit√© IA: {prob * 100:.1f}%")
                            
                        except Exception as e:
                            print(f"Erreur lors de l'analyse de {file_path}: {e}")
                            writer.writerow([file_path, "ERREUR", "ERREUR", "ERREUR"])
                
                print(f"\nR√©sultats enregistr√©s dans {output_path}")
                
            except Exception as e:
                print(f"Erreur lors du traitement par lots: {e}")
                
        elif choice == '4':
            print("\nMerci d'avoir utilis√© FastDetectGPT!")
            break
            
        else:
            print("\nOption non valide. Veuillez choisir entre 1 et 4.")

def calibrate_model_parameters(args, dataset_path):
    """
    Calibre les param√®tres de r√©gression logistique pour une paire de mod√®les
    
    Args:
        args: Arguments contenant reference_model_name et scoring_model_name
        dataset_path: Chemin vers un dataset contenant des textes humains et IA
    
    Returns:
        tuple: (k, b) param√®tres de la r√©gression logistique
    """
    from sklearn.linear_model import LogisticRegression
    import pandas as pd
    import numpy as np
    from tqdm import tqdm
    
    # Initialiser le d√©tecteur avec les mod√®les sp√©cifi√©s
    detector = FastDetectGPT(args)
    
    print(f"Calibration de la paire de mod√®les: {args.reference_model_name}_{args.scoring_model_name}")
    
    # Charger le dataset (format attendu: colonne 'text' et colonne 'label' avec 0=humain, 1=IA)
    try:
        data = pd.read_csv(dataset_path)
        print(f"Dataset charg√©: {len(data)} √©chantillons")
    except:
        print(f"Erreur: Impossible de charger {dataset_path}")
        return None, None
    
    # V√©rifier les colonnes n√©cessaires
    required_cols = ['text', 'label']
    if not all(col in data.columns for col in required_cols):
        print(f"Erreur: Le dataset doit contenir les colonnes {required_cols}")
        return None, None
    
    # Calculer le crit√®re pour chaque texte
    print("Calcul des crit√®res pour les √©chantillons...")
    crits = []
    for text in tqdm(data['text']):
        try:
            crit, _ = detector.compute_crit(text)
            crits.append(crit)
        except Exception as e:
            print(f"Erreur lors du calcul du crit√®re: {e}")
            crits.append(np.nan)
    
    # Supprimer les valeurs NaN
    valid_indices = ~np.isnan(crits)
    crits_clean = np.array([c for c, v in zip(crits, valid_indices) if v])
    labels_clean = np.array([l for l, v in zip(data['label'], valid_indices) if v])
    
    print(f"Utilisation de {len(crits_clean)}/{len(crits)} √©chantillons valides pour la calibration")
    
    # Entra√Æner la r√©gression logistique
    X = crits_clean.reshape(-1, 1)
    y = labels_clean
    
    model = LogisticRegression()
    model.fit(X, y)
    
    # Extraire les param√®tres (k=coefficient, b=intercept)
    k = model.coef_[0][0]
    b = model.intercept_[0]
    
    # √âvaluer la pr√©cision
    y_pred = model.predict(X)
    accuracy = (y_pred == y).mean()
    
    print(f"R√©sultats de la calibration:")
    print(f"k: {k:.2f}, b: {b:.2f}, pr√©cision: {accuracy:.2f}")
    
    return k, b

def main():
    parser = argparse.ArgumentParser(description="FastDetectGPT - D√©tecteur de texte g√©n√©r√© par IA")
    
    # Options principales
    parser.add_argument('--mode', type=str, choices=['interactive', 'batch', 'calibrate'], default='interactive',
                        help="Mode d'ex√©cution (interactive, batch, calibrate)")
    parser.add_argument('--reference_model_name', type=str, default="deepseek-v3-7b",
                        help="Nom du mod√®le de r√©f√©rence")
    parser.add_argument('--scoring_model_name', type=str, default="deepseek-v3-7b-chat",
                        help="Nom du mod√®le de scoring")
    
    # Options de p√©riph√©rique et performance
    device_group = parser.add_argument_group('Options de p√©riph√©rique')
    device_group.add_argument('--device', type=str, default="auto",
                             help="P√©riph√©rique √† utiliser (cuda, cpu, mps, auto)")
    device_group.add_argument('--quantize', action='store_true',
                             help="Activer la quantification 8-bit (√©conomise de la m√©moire)")
    device_group.add_argument('--cache_dir', type=str, default="../cache",
                             help="R√©pertoire de cache pour les mod√®les")
    
    # Options pour le mode batch
    batch_group = parser.add_argument_group('Options pour le mode batch')
    batch_group.add_argument('--input_dir', type=str,
                            help="R√©pertoire contenant les fichiers √† analyser")
    batch_group.add_argument('--file_pattern', type=str, default="*.txt",
                            help="Motif des fichiers √† analyser")
    batch_group.add_argument('--output_file', type=str, default="results.csv",
                            help="Fichier de sortie pour les r√©sultats batch")
    
    # Options pour le mode calibration
    calib_group = parser.add_argument_group('Options pour la calibration')
    calib_group.add_argument('--dataset_path', type=str,
                            help="Chemin vers le dataset de calibration")
    
    args = parser.parse_args()
    
    # D√©tection automatique du p√©riph√©rique
    if args.device == 'auto':
        if torch.cuda.is_available():
            args.device = 'cuda'
            print("CUDA d√©tect√© - utilisation du GPU")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            args.device = 'mps'
            print("Apple Silicon d√©tect√© - utilisation de MPS")
        else:
            args.device = 'cpu'
            print("Aucun acc√©l√©rateur d√©tect√© - utilisation du CPU")
    
    # Ex√©cution selon le mode
    if args.mode == 'interactive':
        run_improved(args)
        
    elif args.mode == 'batch':
        if not args.input_dir:
            print("Erreur: --input_dir est requis en mode batch")
            return
            
        import glob
        import os
        import csv
        
        # V√©rifier le r√©pertoire d'entr√©e
        if not os.path.isdir(args.input_dir):
            print(f"Erreur: {args.input_dir} n'est pas un r√©pertoire valide")
            return
            
        # Initialiser le d√©tecteur
        detector = FastDetectGPT(args)
        
        # Trouver les fichiers
        files = glob.glob(os.path.join(args.input_dir, args.file_pattern))
        if not files:
            print(f"Aucun fichier correspondant √† {args.file_pattern} trouv√© dans {args.input_dir}")
            return
            
        print(f"Analyse de {len(files)} fichiers...")
        
        # Cr√©er le r√©pertoire de sortie si n√©cessaire
        output_dir = os.path.dirname(args.output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        # Analyser les fichiers
        with open(args.output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Fichier', 'Probabilit√© IA (%)', 'Score', 'Tokens'])
            
            for file_path in files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        text = f.read()
                    
                    prob, crit, ntokens = detector.compute_prob(text)
                    writer.writerow([file_path, f"{prob * 100:.1f}", f"{crit:.4f}", ntokens])
                    print(f"Analys√©: {file_path} - Probabilit√© IA: {prob * 100:.1f}%")
                    
                except Exception as e:
                    print(f"Erreur lors de l'analyse de {file_path}: {e}")
                    writer.writerow([file_path, "ERREUR", "ERREUR", "ERREUR"])
            
        print(f"R√©sultats enregistr√©s dans {args.output_file}")
        
    elif args.mode == 'calibrate':
        if not args.dataset_path:
            print("Erreur: --dataset_path est requis en mode calibrate")
            return
            
        k, b = calibrate_model_parameters(args, args.dataset_path)
        if k is not None and b is not None:
            print("\nPour utiliser ces param√®tres calibr√©s, ajoutez la ligne suivante dans fast_detect_gpt.py:")
            print(f"'{args.reference_model_name}_{args.scoring_model_name}': ({k:.2f}, {b:.2f}),")

if __name__ == "__main__":
    main()
